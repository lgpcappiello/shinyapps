#generate Z based on logit{P(Z=1|X^{dagger})} = f(X^{dagger})
z0 <- rbinom(N, 1, expit(xdag[,1] - xdag[,2] + xdag[,3]))
#take random samples of X (xh) from X^{dagger}|Z=0 and X* (xc) from X^{dagger}|Z=1 for each PS setting
# We will start with settion 0 - the other settings are commented out for now.
#also add column of 1s to X (for intercepts)
X <- cbind(rep(1,nh), xdag[sample(which(z0==0), nh), ]) #PS 0
X.new <- cbind(rep(1,nc), xdag[sample(which(z0==1), nc), ])
# convert to data frames so R knows how to use it later
X <- data.frame(X)
X.new <- data.frame(X.new)
#functions for generating y
f.y0 <- function(x){ -0.5 + x[,2]           + x[,4] } #OR 0
#generate y based on functions (two OR settings) above plus random error
# We will start with settion 0 - the other settings are commented out for now.
y <- f.y0(X) + rnorm(nh) #ps0, or0
# True values (target values for estimators)
mu00 <- mean(f.y0(X.new)) + alph*(var(f.y0(X)) + 1)
n <- nrow(X); n.new <- nrow(X.new)
grp <- c(rep(0,n),rep(1,n.new))
X.all <- rbind(X, X.new)
# get values of r hat
ps.model <- glm(grp~., data=X.all, family=binomial())
grp.hat <- ps.model$fitted.values[1:n]
r.hat <- exp(logit(grp.hat)-log(n.new/n))
# get values of m hat
m.mod <- glm(y~., data=X, family=fam)
m.hat <- m.mod$fitted.values
# calculate mu star hat, weighting method
pe <- exp(-((alph^2)*var(y))/2)*mean(y*exp(alph*(y - m.hat))*r.hat)
return(c(mu00,pe))
}
# target <- function(a, x, f){ mean(f(x) * exp(a*f(x))) / mean(exp(a*f(x))) }
## logit
logit <- function(u) log(u/(1-u))
## inverse logit
expit <- function(u) exp(u)/(1+exp(u))
nrep <- 1000
alph <- runif(nrep, -1, 1)
wtd.ests00 <- sapply(alph, sens.wtd, 100, 100)
head(wtd.ests)
head(wtd.ests00)
wtd.ests[,1:4]
wtd.ests00[,1:4]
wtd.ests <- sapply(alph, sens.wtd, 100, 100)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests); lines(alph, truemu, col='red')
plot(alph, truemu)
hist(alph)
nrep <- 1000
alph <- runif(nrep, -1, 1)
wtd.ests <- sapply(alph, sens.wtd, 1000, 1000)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests); lines(alph, truemu, col='red')
## Modified weighting estimator
sens.wtd <- function(alph, nc, nh, fam=gaussian()){
## Generate data
N <- 10*nh
#generate X^{dagger} from trivariate standard normal
xdag <- rmvnorm(N, mean=c(0,0,0), sigma=diag(3))
#generate Z based on logit{P(Z=1|X^{dagger})} = f(X^{dagger})
z0 <- rbinom(N, 1, expit(xdag[,1] - xdag[,2] + xdag[,3]))
#take random samples of X (xh) from X^{dagger}|Z=0 and X* (xc) from X^{dagger}|Z=1 for each PS setting
# We will start with settion 0 - the other settings are commented out for now.
#also add column of 1s to X (for intercepts)
X <- cbind(rep(1,nh), xdag[sample(which(z0==0), nh), ]) #PS 0
X.new <- cbind(rep(1,nc), xdag[sample(which(z0==1), nc), ])
# convert to data frames so R knows how to use it later
X <- data.frame(X)
X.new <- data.frame(X.new)
#functions for generating y
f.y0 <- function(x){ -0.5 + x[,2]           + x[,4] } #OR 0
#generate y based on functions (two OR settings) above plus random error
# We will start with settion 0 - the other settings are commented out for now.
y <- f.y0(X) + rnorm(nh) #ps0, or0
# True values (target values for estimators)
mu00 <- mean(f.y0(X.new)) + alph*(var(f.y0(X)))
n <- nrow(X); n.new <- nrow(X.new)
grp <- c(rep(0,n),rep(1,n.new))
X.all <- rbind(X, X.new)
# get values of r hat
ps.model <- glm(grp~., data=X.all, family=binomial())
grp.hat <- ps.model$fitted.values[1:n]
r.hat <- exp(logit(grp.hat)-log(n.new/n))
# get values of m hat
m.mod <- glm(y~., data=X, family=fam)
m.hat <- m.mod$fitted.values
# calculate mu star hat, weighting method
pe <- exp(-((alph^2)*var(y))/2)*mean(y*exp(alph*(y - m.hat))*r.hat)
return(c(mu00,pe))
}
# target <- function(a, x, f){ mean(f(x) * exp(a*f(x))) / mean(exp(a*f(x))) }
## logit
logit <- function(u) log(u/(1-u))
## inverse logit
expit <- function(u) exp(u)/(1+exp(u))
nrep <- 1000
alph <- runif(nrep, -1, 1)
wtd.ests <- sapply(alph, sens.wtd, 1000, 1000)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests); lines(alph, truemu, col='red')
plot(alph, truemu)
nrep <- 10000
alph <- runif(nrep, -1, 1)
wtd.ests <- sapply(alph, sens.wtd, 1000, 1000)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests); lines(alph, truemu, col='red')
nrep <- 1000
alph <- runif(nrep, -1, 1)
wtd.ests <- sapply(alph, sens.wtd, 1000, 1000)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests); abline(truemu ~ alph, col='red')
abline(truemu ~ alph, col='red')
plot(alph, truemu)
plot(alph, ests); abline(lm(truemu ~ alph), col='red')
plot(alph, ests, ylim=c(4,4)); abline(lm(truemu ~ alph), col='red')
plot(alph, ests, ylim=c(-4,4)); abline(lm(truemu ~ alph), col='red')
plot(alph, truemu)
summary(lm(trumu~alph))
summary(lm(truemu~alph))
nrep <- 10000
alph <- runif(nrep, -1, 1)
wtd.ests <- sapply(alph, sens.wtd, 1000, 1000)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests, ylim=c(-4,4)); abline(lm(truemu ~ alph), col='red')
(31/36)^30
set.seed(0)
library(mvtnorm)
## Modified weighting estimator
sens.wtd <- function(alph, nc, nh, fam=gaussian()){
## Generate data
N <- 10*nh
#generate X^{dagger} from trivariate standard normal
xdag <- rmvnorm(N, mean=c(0,0,0), sigma=diag(3))
#generate Z based on logit{P(Z=1|X^{dagger})} = f(X^{dagger})
z0 <- rbinom(N, 1, expit(xdag[,1] - xdag[,2] + xdag[,3]))
#take random samples of X (xh) from X^{dagger}|Z=0 and X* (xc) from X^{dagger}|Z=1 for each PS setting
# We will start with settion 0 - the other settings are commented out for now.
#also add column of 1s to X (for intercepts)
X <- cbind(rep(1,nh), xdag[sample(which(z0==0), nh), ]) #PS 0
X.new <- cbind(rep(1,nc), xdag[sample(which(z0==1), nc), ])
# convert to data frames so R knows how to use it later
X <- data.frame(X)
X.new <- data.frame(X.new)
#functions for generating y
f.y0 <- function(x){ -0.5 + x[,2]           + x[,4] } #OR 0
#generate y based on functions (two OR settings) above plus random error
# We will start with settion 0 - the other settings are commented out for now.
y <- f.y0(X) + rnorm(nh) #ps0, or0
# True values (target values for estimators)
mu00 <- mean(f.y0(X.new)) + alph*(var(f.y0(X)))
n <- nrow(X); n.new <- nrow(X.new)
grp <- c(rep(0,n),rep(1,n.new))
X.all <- rbind(X, X.new)
# get values of r hat
ps.model <- glm(grp~., data=X.all, family=binomial())
grp.hat <- ps.model$fitted.values[1:n]
r.hat <- exp(logit(grp.hat)-log(n.new/n))
# get values of m hat
m.mod <- glm(y~., data=X, family=fam)
m.hat <- m.mod$fitted.values
# calculate mu star hat, weighting method
pe <- exp(-((alph^2)*var(y))/2)*mean(y*exp(alph*(y - m.hat))*r.hat)
return(c(mu00,pe))
}
# target <- function(a, x, f){ mean(f(x) * exp(a*f(x))) / mean(exp(a*f(x))) }
## logit
logit <- function(u) log(u/(1-u))
## inverse logit
expit <- function(u) exp(u)/(1+exp(u))
nrep <- 10000
alph <- runif(nrep, -1, 1)
wtd.ests <- sapply(alph, sens.wtd, 1000, 1000)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests, ylim=c(-4,4)); abline(lm(truemu ~ alph), col='red')
set.seed(0)
library(mvtnorm)
## Modified weighting estimator
sens.wtd <- function(alph, nc, nh, fam=gaussian()){
## Generate data
N <- 10*nh
#generate X^{dagger} from trivariate standard normal
xdag <- rmvnorm(N, mean=c(0,0,0), sigma=diag(3))
#generate Z based on logit{P(Z=1|X^{dagger})} = f(X^{dagger})
z0 <- rbinom(N, 1, expit(xdag[,1] - xdag[,2] + xdag[,3]))
#take random samples of X (xh) from X^{dagger}|Z=0 and X* (xc) from X^{dagger}|Z=1 for each PS setting
# We will start with settion 0 - the other settings are commented out for now.
#also add column of 1s to X (for intercepts)
X <- cbind(rep(1,nh), xdag[sample(which(z0==0), nh), ]) #PS 0
X.new <- cbind(rep(1,nc), xdag[sample(which(z0==1), nc), ])
# convert to data frames so R knows how to use it later
X <- data.frame(X)
X.new <- data.frame(X.new)
#functions for generating y
f.y0 <- function(x){ -0.5 + x[,2]           + x[,4] } #OR 0
#generate y based on functions (two OR settings) above plus random error
# We will start with settion 0 - the other settings are commented out for now.
y <- f.y0(X) + rnorm(nh) #ps0, or0
# True values (target values for estimators)
mu00 <- mean(f.y0(X.new)) + alph*(var(f.y0(X)))
n <- nrow(X); n.new <- nrow(X.new)
grp <- c(rep(0,n),rep(1,n.new))
X.all <- rbind(X, X.new)
# get values of r hat
ps.model <- glm(grp~., data=X.all, family=binomial())
grp.hat <- ps.model$fitted.values[1:n]
r.hat <- exp(logit(grp.hat)-log(n.new/n))
# get values of m hat
m.mod <- glm(y~., data=X, family=fam)
m.hat <- m.mod$fitted.values
# calculate mu star hat, weighting method
pe <- exp(-((alph^2)*var(y))/2)*mean(y*exp(alph*(y - m.hat))*r.hat)
return(c(mu00,pe))
}
# target <- function(a, x, f){ mean(f(x) * exp(a*f(x))) / mean(exp(a*f(x))) }
## logit
logit <- function(u) log(u/(1-u))
## inverse logit
expit <- function(u) exp(u)/(1+exp(u))
nrep <- 1000
alph <- runif(nrep, -1, 1)
wtd.ests <- sapply(alph, sens.wtd, 1000, 1000)
truemu <- wtd.ests[1,]
ests <- wtd.ests[2,]
plot(alph, ests, ylim=c(-4,4)); abline(lm(truemu ~ alph), col='red')
shiny::runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp()
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp()
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
boxplot(iris$Sepal.Length)
test <- boxplot(iris$Sepal.Length)
test <- boxplot(iris$Sepal.Width)
test$out
test
print(test)
View(test)
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
summary(aov(z.ij ~ groups))
}
## Test with iris dataset
boxplot(iris$Sepal.Length ~ iris$Species)
bftest(values = iris$Sepal.Length, groups = iris$Species)
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
summary(aov(z.ij ~ groups))
}
bftest(values = iris$Sepal.Length, groups = iris$Species)
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
summary(aov(z.ij ~ groups))
}
## Test with iris dataset
boxplot(iris$Sepal.Length ~ iris$Species)
bftest(values = iris$Sepal.Length, groups = iris$Species)
# R script for Brown-Forsythe test
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
summary(aov(z.ij ~ groups))
}
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
summary(aov(z.ij ~ groups))
}
temp <- iris[iris$Species != "versicolor",]
bftest(temp$Sepal.Length, temp$Species)
# R script for Brown-Forsythe test
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
boxplot(z.ij ~ groups)
summary(aov(z.ij ~ groups))
}
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
boxplot(z.ij ~ groups)
summary(aov(z.ij ~ groups))
}
## Test with iris dataset
boxplot(iris$Sepal.Length ~ iris$Species)
# R script for Brown-Forsythe test
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
boxplot(z.ij ~ groups)
summary(aov(z.ij ~ groups))
}
bftest(values = iris$Sepal.Length, groups = iris$Species)
temp <- iris[iris$Species != "versicolor",]
bftest(temp$Sepal.Length, temp$Species)
# R script for Brown-Forsythe test
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
boxplot(z.ij ~ groups, xlab="absolute differences")
summary(aov(z.ij ~ groups))
}
bftest(values = iris$Sepal.Length, groups = iris$Species)
## Test with iris dataset
bftest(values = iris$Sepal.Length, groups = iris$Species)
# R script for Brown-Forsythe test
bftest <- function(values, groups, alpha = 0.05, na.rm = TRUE){
grouplabs <- levels(factor((groups)))
p <- length(grouplabs)
z.ij <- numeric(length=0)
for(i in 1:p){
z.ij <- c(z.ij,abs(values[groups == grouplabs[i]] - median(values[groups == grouplabs[i]])))
}
boxplot(z.ij ~ groups, ylab="absolute differences")
summary(aov(z.ij ~ groups))
}
## Test with iris dataset
bftest(values = iris$Sepal.Length, groups = iris$Species)
## Test with iris dataset
boxplot(iris$Sepal.Length ~ iris$Species)
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp()
runApp()
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp()
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
?dnorm
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp()
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp()
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
runApp()
runApp('OneDrive - California State University, Sacramento/Documents/CLT Shiny/NormalApproxBinom')
setwd("~/Documents/GitHub/shinyapps/NormalApproxBinom")
setwd("~/Documents/GitHub/shinyapps/NormalApproxBinom")
runApp()
setwd("~/Documents/GitHub/shinyapps/NormalApproxBinom")
runApp()
runApp()
?qbinom
1:4
c(1:4)
runApp()
?prnom
?pnorm
runApp()
pbinom(2, 2, 0.05)
pbinom(1, 2, 0.05)
pbinom(0, 2, 0.05)
sum(dbinom(1:4, 2, 0.4)
)
pbinom(4, 2, 0.4)
dbinom(1:4, 2, 0.4)
dbinom(0:4, 2, 0.4)
dbinom(0:2, 4, 0.4)
pbinom(2, 4, 0.4)
sum(dbinom(0:2, 4, 0.4))
runApp()
setwd("~/Documents/GitHub/shinyapps/SimulateCLT")
runApp()
samples <- sapply(rep(10, 1000), rbinom, 10, 0.5, simplify='array')
means <- colMeans(samples)
meandat <- as.data.frame(means)
mu <- 0.5*10
sig <- sqrt(10*0.5*0.5)
ggplot(meandat,
aes(x = means),
environment=environment()) +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_histogram(binwidth=1,
colour="black",
fill="lightgrey") +
scale_y_continuous(name = NULL, labels=NULL) +
stat_function(fun = dnorm,
args = list(mean = mu,
sd = sigma)
)
ggplot(meandat,
aes(x = means),
environment=environment()) +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_histogram(binwidth=1,
colour="black",
fill="lightgrey") +
scale_y_continuous(name = NULL, labels=NULL) +
stat_function(fun = dnorm,
args = list(mean = mu,
sd = sig)
)
runApp()
ggplot(meandat,
aes(x = means),
environment=environment()) +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_histogram(binwidth=1,
colour="black",
fill="lightgrey") +
scale_y_continuous(name = NULL, labels=NULL) +
stat_function(fun = dnorm,
args = list(mean = mu,
sd = sig)
)
samples <- sapply(rep(100, 1000), rbinom, 10, 0.5, simplify='array')
means <- colMeans(samples)
meandat <- as.data.frame(means)
ggplot(meandat,
aes(x = means, y = ..density..),
environment=environment()) +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_histogram(binwidth=1,
colour="black",
fill="lightgrey") +
scale_y_continuous(name = NULL, labels=NULL) +
stat_function(fun = dnorm,
args = list(mean = mu,
sd = sig)
)
ggplot(meandat,
aes(x = means, y = ..density..),
environment=environment()) +
theme_bw() +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_histogram(binwidth=1,
colour="black",
fill="lightgrey") #+
runApp()
runApp()
runApp()
runApp()
runApp()
df <- data.frame(PF = 10*rnorm(1000))
ggplot(df, aes(x = PF)) +
geom_histogram(aes(y =..density..),
breaks = seq(-50, 50, by = 10),
colour = "black",
fill = "white") +
stat_function(fun = dnorm, args = list(mean = mean(df$PF), sd = sd(df$PF)))
runApp()
runApp()
runApp()
install.packages("devtools")
#Install R Package
devtools::install_github("ucrgradstat/ucrstats")
install.packages("devtools")
devtools::install_github("ucrgradstat/ucrstats")
library(ucrstats)
list_tutorials
list_tutorials()
access_tutorial("lme_model")
